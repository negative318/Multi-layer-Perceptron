{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54000, 784) (54000, 10)\n",
      "(10000, 784) (10000, 10)\n",
      "(6000, 784) (6000, 10)\n"
     ]
    }
   ],
   "source": [
    "from MLP_autograd import *\n",
    "from keras.datasets import mnist\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train /255.0\n",
    "x_test = x_test /255.0\n",
    "x_validation = x_train[:6000]\n",
    "y_validation = y_train[:6000]\n",
    "x_train = x_train[6000:]\n",
    "y_train = y_train[6000:]\n",
    "\n",
    "x_validation = x_validation.reshape(x_validation.shape[0],-1)\n",
    "x_train = x_train.reshape(x_train.shape[0],-1)\n",
    "x_test = x_test.reshape(x_test.shape[0],-1)\n",
    "\n",
    "\n",
    "def one_hot(Y):\n",
    "  one_hot_Y = np.zeros((Y.size,np.max(Y) + 1))\n",
    "  one_hot_Y[np.arange(Y.size),Y] = 1\n",
    "  return one_hot_Y\n",
    "\n",
    "y_train = one_hot(y_train)\n",
    "y_validation = one_hot(y_validation)\n",
    "y_test = one_hot(y_test)\n",
    "\n",
    "\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape,y_test.shape)\n",
    "print(x_validation.shape,y_validation.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss:  10.903228808971036 Accuracy train:  0.1015625 Accuracy validation:  0.0645\n",
      "100 loss:  0.5887354575760202 Accuracy train:  0.8671875 Accuracy validation:  0.7955\n",
      "200 loss:  0.4130588682494293 Accuracy train:  0.890625 Accuracy validation:  0.839\n",
      "300 loss:  0.3446710266869586 Accuracy train:  0.90625 Accuracy validation:  0.857\n",
      "400 loss:  0.3109964381667565 Accuracy train:  0.9140625 Accuracy validation:  0.8653333333333333\n",
      "500 loss:  0.29014756937328456 Accuracy train:  0.9140625 Accuracy validation:  0.8695\n",
      "600 loss:  0.27523532242984894 Accuracy train:  0.921875 Accuracy validation:  0.8776666666666667\n",
      "700 loss:  0.2636611859902905 Accuracy train:  0.921875 Accuracy validation:  0.8838333333333334\n",
      "800 loss:  0.25416489742242976 Accuracy train:  0.9296875 Accuracy validation:  0.8875\n",
      "900 loss:  0.24609198219490375 Accuracy train:  0.9375 Accuracy validation:  0.8901666666666667\n",
      "1000 loss:  0.23909409608905613 Accuracy train:  0.9375 Accuracy validation:  0.8925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8889"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NeuralNetwork(layers_size=[28*28, 10],activations = [\"softmax\"],lossFunction = \"crossEntropy\", l_rate=0.01)\n",
    "nn.train(x_train, y_train, x_validation, y_validation, epochs=1001, batch_size=128)\n",
    "nn.test(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss:  11.856681578703316 Accuracy train:  0.1171875 Accuracy validation:  0.09366666666666666\n",
      "100 loss:  0.38365572380026924 Accuracy train:  0.90625 Accuracy validation:  0.8536666666666667\n",
      "200 loss:  0.2486834914401742 Accuracy train:  0.9140625 Accuracy validation:  0.8748333333333334\n",
      "300 loss:  0.20402150429776414 Accuracy train:  0.9296875 Accuracy validation:  0.8911666666666667\n",
      "400 loss:  0.18346819841370804 Accuracy train:  0.9375 Accuracy validation:  0.9011666666666667\n",
      "500 loss:  0.16863833517741808 Accuracy train:  0.9453125 Accuracy validation:  0.9061666666666667\n",
      "600 loss:  0.15848557241656622 Accuracy train:  0.9453125 Accuracy validation:  0.909\n",
      "700 loss:  0.15087728611567436 Accuracy train:  0.96875 Accuracy validation:  0.9111666666666667\n",
      "800 loss:  0.14337352770229825 Accuracy train:  0.96875 Accuracy validation:  0.9133333333333333\n",
      "900 loss:  0.1367786115418952 Accuracy train:  0.96875 Accuracy validation:  0.9155\n",
      "1000 loss:  0.13102776850529285 Accuracy train:  0.96875 Accuracy validation:  0.9176666666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9201"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NeuralNetwork(layers_size=[28*28,64, 10],activations = [\"relu\", \"softmax\"],lossFunction = \"crossEntropy\", l_rate=0.01)\n",
    "nn.train(x_train, y_train,x_validation, y_validation, epochs=1001,batch_size = 128)\n",
    "nn.test(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss:  12.344528380798117 Accuracy train:  0.09375 Accuracy validation:  0.11966666666666667\n",
      "100 loss:  0.09218741574333832 Accuracy train:  0.9609375 Accuracy validation:  0.9296666666666666\n",
      "200 loss:  0.04942720075848736 Accuracy train:  0.9921875 Accuracy validation:  0.9386666666666666\n",
      "300 loss:  0.030681250679184875 Accuracy train:  1.0 Accuracy validation:  0.9428333333333333\n",
      "400 loss:  0.021408195183310656 Accuracy train:  1.0 Accuracy validation:  0.9445\n",
      "500 loss:  0.014634390004557818 Accuracy train:  1.0 Accuracy validation:  0.9463333333333334\n",
      "600 loss:  0.010290391398576074 Accuracy train:  1.0 Accuracy validation:  0.9468333333333333\n",
      "700 loss:  0.007967432671558632 Accuracy train:  1.0 Accuracy validation:  0.9485\n",
      "800 loss:  0.006372734702181753 Accuracy train:  1.0 Accuracy validation:  0.9496666666666667\n",
      "900 loss:  0.005400915375682865 Accuracy train:  1.0 Accuracy validation:  0.9496666666666667\n",
      "1000 loss:  0.0048008183673879535 Accuracy train:  1.0 Accuracy validation:  0.9496666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9558"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NeuralNetwork(layers_size=[28*28, 128, 10],activations = [\"relu\", \"softmax\"],lossFunction = \"crossEntropy\", l_rate=0.1)\n",
    "nn.train(x_train, y_train,x_validation, y_validation, epochs=1001,batch_size = 128)\n",
    "nn.test(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss:  12.952041085591537 Accuracy train:  0.0625 Accuracy validation:  0.08533333333333333\n",
      "100 loss:  0.35439000235859186 Accuracy train:  0.90625 Accuracy validation:  0.8625\n",
      "200 loss:  0.3071375990724091 Accuracy train:  0.921875 Accuracy validation:  0.8825\n",
      "300 loss:  0.2901142558872444 Accuracy train:  0.9296875 Accuracy validation:  0.8926666666666667\n",
      "400 loss:  0.2721076409590791 Accuracy train:  0.9375 Accuracy validation:  0.8998333333333334\n",
      "500 loss:  0.2584285329773692 Accuracy train:  0.9453125 Accuracy validation:  0.9046666666666666\n",
      "600 loss:  0.24871227219424377 Accuracy train:  0.9453125 Accuracy validation:  0.9106666666666666\n",
      "700 loss:  0.24059189289965074 Accuracy train:  0.953125 Accuracy validation:  0.9145\n",
      "800 loss:  0.2323380128062395 Accuracy train:  0.953125 Accuracy validation:  0.9186666666666666\n",
      "900 loss:  0.22562306537780807 Accuracy train:  0.9609375 Accuracy validation:  0.9216666666666666\n",
      "1000 loss:  0.2200700922251682 Accuracy train:  0.9609375 Accuracy validation:  0.9235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9194"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NeuralNetwork(layers_size=[28*28, 128, 64, 10],activations = [\"relu\",\"relu\", \"softmax\"],lossFunction = \"crossEntropy\", l_rate=0.01)\n",
    "nn.train(x_train, y_train,x_validation, y_validation, epochs=1001,batch_size = 128)\n",
    "nn.test(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44000, 3072) (44000, 10)\n",
      "(10000, 3072) (10000, 10)\n",
      "(6000, 3072) (6000, 10)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from MLP_autograd import *\n",
    "from keras.datasets import cifar10\n",
    "(x_train,y_train),(x_test,y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train /255.0\n",
    "x_test = x_test /255.0\n",
    "x_validation = x_train[:6000]\n",
    "y_validation = y_train[:6000]\n",
    "x_train = x_train[6000:]\n",
    "y_train = y_train[6000:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_validation = x_validation.reshape(x_validation.shape[0],-1)\n",
    "x_train = x_train.reshape(x_train.shape[0],-1)\n",
    "x_test = x_test.reshape(x_test.shape[0],-1)\n",
    "\n",
    "\n",
    "\n",
    "def one_hot(Y):\n",
    "  one_hot_Y = np.zeros((Y.size,np.max(Y) + 1))\n",
    "  one_hot_Y[np.arange(Y.size),Y] = 1\n",
    "  return one_hot_Y\n",
    "\n",
    "y_train = one_hot(y_train.T)\n",
    "y_validation = one_hot(y_validation.T)\n",
    "y_test = one_hot(y_test.T)\n",
    "\n",
    "\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape,y_test.shape)\n",
    "print(x_validation.shape,y_validation.shape)\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss:  11.872711784901881 Accuracy train:  0.140625 Accuracy validation:  0.13566666666666666\n",
      "1 loss:  11.932816784093637 Accuracy train:  0.1015625 Accuracy validation:  0.21166666666666667\n",
      "2 loss:  11.42549587869198 Accuracy train:  0.1484375 Accuracy validation:  0.2235\n",
      "3 loss:  10.944459747487816 Accuracy train:  0.1640625 Accuracy validation:  0.22966666666666666\n",
      "4 loss:  10.959442639817777 Accuracy train:  0.1640625 Accuracy validation:  0.23916666666666667\n",
      "5 loss:  10.399806073331067 Accuracy train:  0.2109375 Accuracy validation:  0.24133333333333334\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(layers_size=[32*32*3, 512, 10],activations = [\"relu\", \"softmax\"],lossFunction = \"crossEntropy\", l_rate=0.01)\n",
    "nn.train(x_train, y_train,x_validation, y_validation, epochs=1001,batch_size = 128)\n",
    "nn.test(x_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

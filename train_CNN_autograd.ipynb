{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(1000, 1, 28, 28) (1000, 10)\n",
      "(1000, 1, 28, 28) (1000, 10)\n",
      "(10000, 1, 28, 28) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from MLP_autograd import *\n",
    "from CNN_autograd import *\n",
    "from keras.datasets import mnist\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "\n",
    "def one_hot(Y):\n",
    "  one_hot_Y = np.zeros((Y.size,np.max(Y) + 1))\n",
    "  one_hot_Y[np.arange(Y.size),Y] = 1\n",
    "  return one_hot_Y\n",
    "\n",
    "print(y_train.shape)\n",
    "\n",
    "y_train = one_hot(y_train)\n",
    "y_test = one_hot(y_test)\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "x_validation = x_train[59000:60000]\n",
    "y_validation = y_train[59000:60000,:]\n",
    "x_train = x_train[0:1000]\n",
    "y_train = y_train[0:1000,:]\n",
    "\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0],1,28,28)\n",
    "x_validation = x_validation.reshape(x_validation.shape[0],1,28,28)\n",
    "x_test = x_test.reshape(x_test.shape[0],1,28,28)\n",
    "\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_validation.shape, y_validation.shape)\n",
    "print(x_test.shape,y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "CNN1 = Convolutional(input_shape = (1,28,28), kernel_size = 3, output_depth = 4, l_rate = 0.01, activeFuncion = \"relu\")\n",
    "pool1 = MaxPoolingLayer(2)\n",
    "CNN2 = Convolutional(input_shape = (4,13,13), kernel_size = 3,output_depth = 8, l_rate = 0.01, activeFuncion = \"relu\")\n",
    "pool2 = MaxPoolingLayer(2)\n",
    "flatten = Flattening()\n",
    "nn = NeuralNetwork(layers_size=[288,10],activations = [\"softmax\"], lossFunction = \"crossEntropy\", l_rate = 0.01) # 8*6*6 = 288\n",
    "\n",
    "\n",
    "model = Model([CNN1,pool1,CNN2,pool2, flatten,nn])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (1000, 1, 28, 28)\n",
      "y_train:  (1000, 10)\n",
      "x_val:  (1000, 1, 28, 28)\n",
      "y_val:  (1000, 10)\n",
      "epochs:  0 loss_train:  11.130861847151564 accuracy_train: 0.15 loss_val 10.989874514504008 accuracy_validation: 0.155\n",
      "epochs:  1 loss_train:  10.194059717071688 accuracy_train: 0.204 loss_val 10.409550752106668 accuracy_validation: 0.19\n",
      "epochs:  2 loss_train:  9.610334635742683 accuracy_train: 0.225 loss_val 9.94506864648923 accuracy_validation: 0.207\n"
     ]
    }
   ],
   "source": [
    "model.train(x_train,y_train,x_validation,y_validation, batch_size = 64, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.313796771384195, 0.6246)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (1000, 1, 28, 28)\n",
      "y_train:  (10, 1000)\n",
      "x_val:  (1000, 1, 28, 28)\n",
      "y_val:  (10, 1000)\n",
      "epochs:  0 loss_train:  3.549403130588621 accuracy_train: 0.675 loss_val 3.3033738006213116 accuracy_validation: 0.688\n",
      "epochs:  1 loss_train:  3.5169671669525315 accuracy_train: 0.676 loss_val 3.2767712447186153 accuracy_validation: 0.693\n",
      "epochs:  2 loss_train:  3.4846197872847817 accuracy_train: 0.677 loss_val 3.250870223571909 accuracy_validation: 0.692\n",
      "epochs:  3 loss_train:  3.452442182848193 accuracy_train: 0.679 loss_val 3.2256395484873663 accuracy_validation: 0.694\n",
      "epochs:  4 loss_train:  3.42043720341697 accuracy_train: 0.686 loss_val 3.2011125868980232 accuracy_validation: 0.698\n",
      "epochs:  5 loss_train:  3.388809575768997 accuracy_train: 0.687 loss_val 3.177206758807205 accuracy_validation: 0.699\n",
      "epochs:  6 loss_train:  3.3575125921001665 accuracy_train: 0.689 loss_val 3.153844344339591 accuracy_validation: 0.699\n",
      "epochs:  7 loss_train:  3.3266468776041407 accuracy_train: 0.691 loss_val 3.1309869897501046 accuracy_validation: 0.702\n",
      "epochs:  8 loss_train:  3.296093667337395 accuracy_train: 0.696 loss_val 3.108652629900578 accuracy_validation: 0.703\n",
      "epochs:  9 loss_train:  3.265849349916276 accuracy_train: 0.698 loss_val 3.08686508738884 accuracy_validation: 0.705\n",
      "epochs:  10 loss_train:  3.2360584765469453 accuracy_train: 0.704 loss_val 3.0656536389646583 accuracy_validation: 0.708\n",
      "epochs:  11 loss_train:  3.2066820028749334 accuracy_train: 0.707 loss_val 3.045067000922506 accuracy_validation: 0.712\n",
      "epochs:  12 loss_train:  3.1777105056212194 accuracy_train: 0.71 loss_val 3.025073917156882 accuracy_validation: 0.714\n",
      "epochs:  13 loss_train:  3.149206180032346 accuracy_train: 0.712 loss_val 3.005629448682809 accuracy_validation: 0.716\n",
      "epochs:  14 loss_train:  3.1212262818823517 accuracy_train: 0.714 loss_val 2.986702372498495 accuracy_validation: 0.718\n",
      "epochs:  15 loss_train:  3.0938643660879395 accuracy_train: 0.716 loss_val 2.968192230804313 accuracy_validation: 0.718\n",
      "epochs:  16 loss_train:  3.067170487376416 accuracy_train: 0.717 loss_val 2.950110105218307 accuracy_validation: 0.719\n",
      "epochs:  17 loss_train:  3.041181733240729 accuracy_train: 0.718 loss_val 2.932438799125593 accuracy_validation: 0.721\n",
      "epochs:  18 loss_train:  3.0158274013122996 accuracy_train: 0.719 loss_val 2.9152062237766003 accuracy_validation: 0.724\n",
      "epochs:  19 loss_train:  2.9910183454760744 accuracy_train: 0.722 loss_val 2.898413629844429 accuracy_validation: 0.725\n",
      "epochs:  20 loss_train:  2.9667851106343015 accuracy_train: 0.722 loss_val 2.882066781135642 accuracy_validation: 0.726\n",
      "epochs:  21 loss_train:  2.943106458539514 accuracy_train: 0.723 loss_val 2.8662329756085674 accuracy_validation: 0.729\n",
      "epochs:  22 loss_train:  2.9199909716262966 accuracy_train: 0.723 loss_val 2.850890377009141 accuracy_validation: 0.731\n",
      "epochs:  23 loss_train:  2.897379207703257 accuracy_train: 0.727 loss_val 2.8360596309600545 accuracy_validation: 0.732\n",
      "epochs:  24 loss_train:  2.875264641808677 accuracy_train: 0.73 loss_val 2.821849041841726 accuracy_validation: 0.737\n",
      "epochs:  25 loss_train:  2.8536677875385354 accuracy_train: 0.733 loss_val 2.8081028548977045 accuracy_validation: 0.738\n",
      "epochs:  26 loss_train:  2.8325915825163683 accuracy_train: 0.734 loss_val 2.79475423201244 accuracy_validation: 0.739\n",
      "epochs:  27 loss_train:  2.812002289449011 accuracy_train: 0.738 loss_val 2.7817710979065016 accuracy_validation: 0.74\n",
      "epochs:  28 loss_train:  2.7919402377131575 accuracy_train: 0.738 loss_val 2.7691905404246233 accuracy_validation: 0.742\n",
      "epochs:  29 loss_train:  2.7724323436249643 accuracy_train: 0.74 loss_val 2.75697513777892 accuracy_validation: 0.742\n",
      "epochs:  30 loss_train:  2.753432288267616 accuracy_train: 0.741 loss_val 2.745073603391206 accuracy_validation: 0.744\n",
      "epochs:  31 loss_train:  2.734894300755431 accuracy_train: 0.741 loss_val 2.733440936488549 accuracy_validation: 0.746\n",
      "epochs:  32 loss_train:  2.7167974686756526 accuracy_train: 0.743 loss_val 2.7221277460063713 accuracy_validation: 0.747\n",
      "epochs:  33 loss_train:  2.699111792979291 accuracy_train: 0.746 loss_val 2.711045802869117 accuracy_validation: 0.749\n",
      "epochs:  34 loss_train:  2.6817763620527293 accuracy_train: 0.747 loss_val 2.700219918751156 accuracy_validation: 0.749\n",
      "epochs:  35 loss_train:  2.664756115545101 accuracy_train: 0.748 loss_val 2.6895849808655843 accuracy_validation: 0.75\n",
      "epochs:  36 loss_train:  2.648060938774798 accuracy_train: 0.749 loss_val 2.6791279454891592 accuracy_validation: 0.75\n",
      "epochs:  37 loss_train:  2.6316281624337816 accuracy_train: 0.752 loss_val 2.668941432573117 accuracy_validation: 0.751\n",
      "epochs:  38 loss_train:  2.6154642113865156 accuracy_train: 0.754 loss_val 2.6589875193222277 accuracy_validation: 0.753\n",
      "epochs:  39 loss_train:  2.5995586611849806 accuracy_train: 0.755 loss_val 2.649247944943441 accuracy_validation: 0.753\n",
      "epochs:  40 loss_train:  2.583915594109916 accuracy_train: 0.757 loss_val 2.6396829974856697 accuracy_validation: 0.755\n",
      "epochs:  41 loss_train:  2.5685404716971316 accuracy_train: 0.757 loss_val 2.6302830653069296 accuracy_validation: 0.756\n",
      "epochs:  42 loss_train:  2.5534296167309645 accuracy_train: 0.759 loss_val 2.621064999895619 accuracy_validation: 0.756\n",
      "epochs:  43 loss_train:  2.5385778336009803 accuracy_train: 0.76 loss_val 2.6120110090117516 accuracy_validation: 0.756\n",
      "epochs:  44 loss_train:  2.523958839405126 accuracy_train: 0.761 loss_val 2.6031359582537688 accuracy_validation: 0.757\n",
      "epochs:  45 loss_train:  2.50956727925051 accuracy_train: 0.762 loss_val 2.594417549606177 accuracy_validation: 0.759\n",
      "epochs:  46 loss_train:  2.4953985678019714 accuracy_train: 0.764 loss_val 2.585795984392417 accuracy_validation: 0.76\n",
      "epochs:  47 loss_train:  2.4814312098349767 accuracy_train: 0.764 loss_val 2.5772816960460947 accuracy_validation: 0.762\n",
      "epochs:  48 loss_train:  2.4676336207050147 accuracy_train: 0.765 loss_val 2.5688587772350537 accuracy_validation: 0.762\n",
      "epochs:  49 loss_train:  2.453947150506065 accuracy_train: 0.765 loss_val 2.5605547370859476 accuracy_validation: 0.762\n",
      "epochs:  50 loss_train:  2.440422521660024 accuracy_train: 0.766 loss_val 2.5523441782555074 accuracy_validation: 0.762\n",
      "epochs:  51 loss_train:  2.4270459378796487 accuracy_train: 0.768 loss_val 2.544217061156504 accuracy_validation: 0.763\n",
      "epochs:  52 loss_train:  2.4138096106708127 accuracy_train: 0.77 loss_val 2.5361769726481542 accuracy_validation: 0.762\n",
      "epochs:  53 loss_train:  2.400720658568184 accuracy_train: 0.771 loss_val 2.5281983483358386 accuracy_validation: 0.764\n",
      "epochs:  54 loss_train:  2.38777763708183 accuracy_train: 0.773 loss_val 2.5203133160316957 accuracy_validation: 0.764\n",
      "epochs:  55 loss_train:  2.3750091203328223 accuracy_train: 0.776 loss_val 2.5125325766756537 accuracy_validation: 0.765\n",
      "epochs:  56 loss_train:  2.3624209512039505 accuracy_train: 0.776 loss_val 2.5048501487890515 accuracy_validation: 0.766\n",
      "epochs:  57 loss_train:  2.3500078184142286 accuracy_train: 0.776 loss_val 2.497285099801364 accuracy_validation: 0.768\n",
      "epochs:  58 loss_train:  2.337753333544595 accuracy_train: 0.776 loss_val 2.4898248859981402 accuracy_validation: 0.769\n",
      "epochs:  59 loss_train:  2.325650715576026 accuracy_train: 0.776 loss_val 2.482467141884551 accuracy_validation: 0.769\n",
      "epochs:  60 loss_train:  2.3137017424340693 accuracy_train: 0.778 loss_val 2.4752082747155644 accuracy_validation: 0.769\n",
      "epochs:  61 loss_train:  2.3018892240766395 accuracy_train: 0.779 loss_val 2.4680588292112633 accuracy_validation: 0.77\n",
      "epochs:  62 loss_train:  2.2902121196910254 accuracy_train: 0.78 loss_val 2.4610085445135748 accuracy_validation: 0.77\n",
      "epochs:  63 loss_train:  2.278666484586858 accuracy_train: 0.782 loss_val 2.4540750705436003 accuracy_validation: 0.77\n",
      "epochs:  64 loss_train:  2.267259445706669 accuracy_train: 0.784 loss_val 2.4472336745439947 accuracy_validation: 0.773\n",
      "epochs:  65 loss_train:  2.256010663737449 accuracy_train: 0.785 loss_val 2.4404937870236143 accuracy_validation: 0.774\n",
      "epochs:  66 loss_train:  2.244907988583336 accuracy_train: 0.785 loss_val 2.4338864527990203 accuracy_validation: 0.774\n",
      "epochs:  67 loss_train:  2.2339378937376386 accuracy_train: 0.785 loss_val 2.427424260015321 accuracy_validation: 0.774\n",
      "epochs:  68 loss_train:  2.2231093053729305 accuracy_train: 0.786 loss_val 2.421071492865369 accuracy_validation: 0.775\n",
      "epochs:  69 loss_train:  2.212420364615804 accuracy_train: 0.787 loss_val 2.4148305928985985 accuracy_validation: 0.776\n",
      "epochs:  70 loss_train:  2.201853644634776 accuracy_train: 0.788 loss_val 2.4086885136845066 accuracy_validation: 0.776\n",
      "epochs:  71 loss_train:  2.1914580651257967 accuracy_train: 0.788 loss_val 2.4026892062928136 accuracy_validation: 0.776\n",
      "epochs:  72 loss_train:  2.181218463573683 accuracy_train: 0.789 loss_val 2.396833671034683 accuracy_validation: 0.779\n",
      "epochs:  73 loss_train:  2.1711185188215145 accuracy_train: 0.789 loss_val 2.391075744844261 accuracy_validation: 0.779\n",
      "epochs:  74 loss_train:  2.1611392918666676 accuracy_train: 0.791 loss_val 2.3854224768238614 accuracy_validation: 0.779\n",
      "epochs:  75 loss_train:  2.151268649134318 accuracy_train: 0.793 loss_val 2.3797829570430085 accuracy_validation: 0.78\n",
      "epochs:  76 loss_train:  2.1415023527041233 accuracy_train: 0.793 loss_val 2.3742483783738044 accuracy_validation: 0.779\n",
      "epochs:  77 loss_train:  2.1318054779361053 accuracy_train: 0.793 loss_val 2.368820168339854 accuracy_validation: 0.778\n",
      "epochs:  78 loss_train:  2.122228947876687 accuracy_train: 0.797 loss_val 2.363514690558983 accuracy_validation: 0.777\n",
      "epochs:  79 loss_train:  2.1127790079224935 accuracy_train: 0.799 loss_val 2.358317063802178 accuracy_validation: 0.778\n",
      "epochs:  80 loss_train:  2.1034471804740806 accuracy_train: 0.802 loss_val 2.35308598802875 accuracy_validation: 0.779\n",
      "epochs:  81 loss_train:  2.0941997630499603 accuracy_train: 0.803 loss_val 2.347963453643747 accuracy_validation: 0.779\n",
      "epochs:  82 loss_train:  2.0850367330317368 accuracy_train: 0.803 loss_val 2.342933175584731 accuracy_validation: 0.78\n",
      "epochs:  83 loss_train:  2.0759534282688827 accuracy_train: 0.804 loss_val 2.3379665072515947 accuracy_validation: 0.781\n",
      "epochs:  84 loss_train:  2.0669303161670824 accuracy_train: 0.804 loss_val 2.333058260160495 accuracy_validation: 0.781\n",
      "epochs:  85 loss_train:  2.0579512382496814 accuracy_train: 0.805 loss_val 2.328226689143951 accuracy_validation: 0.781\n",
      "epochs:  86 loss_train:  2.0490527072296034 accuracy_train: 0.805 loss_val 2.323433649621553 accuracy_validation: 0.78\n",
      "epochs:  87 loss_train:  2.040243896343345 accuracy_train: 0.807 loss_val 2.3187109650272584 accuracy_validation: 0.781\n",
      "epochs:  88 loss_train:  2.0315393450085515 accuracy_train: 0.807 loss_val 2.3140032414502305 accuracy_validation: 0.782\n",
      "epochs:  89 loss_train:  2.0229214880906308 accuracy_train: 0.807 loss_val 2.309353464106165 accuracy_validation: 0.782\n",
      "epochs:  90 loss_train:  2.0143878210880537 accuracy_train: 0.808 loss_val 2.304735460203561 accuracy_validation: 0.783\n",
      "epochs:  91 loss_train:  2.0059349664995563 accuracy_train: 0.808 loss_val 2.3001669175144497 accuracy_validation: 0.783\n",
      "epochs:  92 loss_train:  1.9975304070643172 accuracy_train: 0.81 loss_val 2.2956515708055294 accuracy_validation: 0.783\n",
      "epochs:  93 loss_train:  1.9892156380424906 accuracy_train: 0.81 loss_val 2.2911779517842588 accuracy_validation: 0.783\n",
      "epochs:  94 loss_train:  1.98096938238909 accuracy_train: 0.811 loss_val 2.2867265644464316 accuracy_validation: 0.783\n",
      "epochs:  95 loss_train:  1.9728020031786937 accuracy_train: 0.81 loss_val 2.2823106669415245 accuracy_validation: 0.783\n",
      "epochs:  96 loss_train:  1.964718393059444 accuracy_train: 0.81 loss_val 2.2779497389289163 accuracy_validation: 0.784\n",
      "epochs:  97 loss_train:  1.956731527469939 accuracy_train: 0.811 loss_val 2.273518900889566 accuracy_validation: 0.785\n",
      "epochs:  98 loss_train:  1.948811621537502 accuracy_train: 0.811 loss_val 2.2690562846717235 accuracy_validation: 0.785\n",
      "epochs:  99 loss_train:  1.9409599826897588 accuracy_train: 0.812 loss_val 2.2646459022472176 accuracy_validation: 0.786\n"
     ]
    }
   ],
   "source": [
    "model.train(x_train,y_train,x_validation,y_validation, batch_size = 64, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.1477497652898787, 0.7179)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (1000, 1, 28, 28)\n",
      "y_train:  (10, 1000)\n",
      "x_val:  (1000, 1, 28, 28)\n",
      "y_val:  (10, 1000)\n",
      "epochs:  0 loss_train:  1.9331792147765656 accuracy_train: 0.811 loss_val 2.260230194697489 accuracy_validation: 0.787\n",
      "epochs:  1 loss_train:  1.9254632849210023 accuracy_train: 0.811 loss_val 2.2557782981832535 accuracy_validation: 0.787\n",
      "epochs:  2 loss_train:  1.9178005908193285 accuracy_train: 0.811 loss_val 2.2513119072636223 accuracy_validation: 0.787\n",
      "epochs:  3 loss_train:  1.9101860779216182 accuracy_train: 0.812 loss_val 2.2468392087256315 accuracy_validation: 0.787\n",
      "epochs:  4 loss_train:  1.9026203171309553 accuracy_train: 0.813 loss_val 2.242431212955219 accuracy_validation: 0.787\n",
      "epochs:  5 loss_train:  1.8950901931704236 accuracy_train: 0.813 loss_val 2.2380229481021705 accuracy_validation: 0.787\n",
      "epochs:  6 loss_train:  1.8875995268971646 accuracy_train: 0.814 loss_val 2.233581964347464 accuracy_validation: 0.787\n",
      "epochs:  7 loss_train:  1.8801672221956982 accuracy_train: 0.814 loss_val 2.2291497039822494 accuracy_validation: 0.788\n",
      "epochs:  8 loss_train:  1.8727775140889797 accuracy_train: 0.815 loss_val 2.2246710562176792 accuracy_validation: 0.788\n",
      "epochs:  9 loss_train:  1.8654370659344044 accuracy_train: 0.817 loss_val 2.220208127346321 accuracy_validation: 0.788\n"
     ]
    }
   ],
   "source": [
    "model.train(x_train,y_train,x_validation,y_validation, batch_size = 64, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.094035373672323, 0.7219)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (1000, 1, 28, 28)\n",
      "y_train:  (10, 1000)\n",
      "x_val:  (1000, 1, 28, 28)\n",
      "y_val:  (10, 1000)\n",
      "epochs:  0 loss_train:  1.8581251081197863 accuracy_train: 0.817 loss_val 2.215828912607686 accuracy_validation: 0.787\n",
      "epochs:  1 loss_train:  1.8508285173898065 accuracy_train: 0.817 loss_val 2.2114493140827824 accuracy_validation: 0.787\n",
      "epochs:  2 loss_train:  1.843582525425278 accuracy_train: 0.818 loss_val 2.2071310379076587 accuracy_validation: 0.787\n",
      "epochs:  3 loss_train:  1.8363829209714144 accuracy_train: 0.818 loss_val 2.202860929217538 accuracy_validation: 0.787\n",
      "epochs:  4 loss_train:  1.8292290213378366 accuracy_train: 0.819 loss_val 2.198582763958567 accuracy_validation: 0.788\n",
      "epochs:  5 loss_train:  1.8221197576097214 accuracy_train: 0.819 loss_val 2.1943666064605445 accuracy_validation: 0.788\n",
      "epochs:  6 loss_train:  1.8150487405575264 accuracy_train: 0.819 loss_val 2.190177244608541 accuracy_validation: 0.788\n",
      "epochs:  7 loss_train:  1.808016468341993 accuracy_train: 0.82 loss_val 2.1860038735725444 accuracy_validation: 0.787\n",
      "epochs:  8 loss_train:  1.801021563595841 accuracy_train: 0.821 loss_val 2.1818765479161844 accuracy_validation: 0.787\n",
      "epochs:  9 loss_train:  1.7940652295898545 accuracy_train: 0.821 loss_val 2.1778035450573343 accuracy_validation: 0.787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.0433446927258547, 0.7256)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(x_train,y_train,x_validation,y_validation, batch_size = 64, epochs = 10)\n",
    "model.test(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3, 32, 32) (10, 1000)\n",
      "(1000, 3, 32, 32) (10, 1000)\n",
      "(10000, 3, 32, 32) (10, 10000)\n"
     ]
    }
   ],
   "source": [
    "from MLP_autograd import *\n",
    "from CNN_autograd import *\n",
    "from keras.datasets import cifar10\n",
    "(x_train,y_train),(x_test,y_test) = cifar10.load_data()\n",
    "x_train = x_train.transpose(0, 3, 1, 2)\n",
    "x_test = x_test.transpose(0, 3, 1, 2)\n",
    "def one_hot(Y):\n",
    "  one_hot_Y = np.zeros((Y.size,np.max(Y) + 1))\n",
    "  one_hot_Y[np.arange(Y.size),Y] = 1\n",
    "  one_hot_Y = one_hot_Y.T\n",
    "  return one_hot_Y\n",
    "\n",
    "\n",
    "y_train = one_hot(y_train.T)\n",
    "y_test = one_hot(y_test)\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "x_validation = x_train[49000:50000]\n",
    "y_validation = y_train[:,49000:50000]\n",
    "x_train = x_train[0:1000]\n",
    "y_train = y_train[:,0:1000]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_validation.shape,y_validation.shape)\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (1000, 3, 32, 32)\n",
      "y_train:  (10, 1000)\n",
      "x_val:  (1000, 3, 32, 32)\n",
      "y_val:  (10, 1000)\n",
      "bias (4, 30, 30)\n",
      "(64, 3, 32, 32) (4, 3, 3, 3) (64, 4, 30, 30)\n",
      "bias (8, 13, 13)\n",
      "(64, 4, 15, 15) (8, 4, 3, 3) (64, 8, 13, 13)\n",
      "b[i]iiiiiiiiiiiiiiiiiiiiiiiiiii (10, 1)\n",
      "aaaaaaa1 (10, 1) (10, 64)\n",
      "aaaaaaaaaaaaaa2 (10, 1) (10, 64)\n",
      "bbbbbbbbbbb1 (10, 64) (10, 64)\n",
      "aaaaaaa1 (64, 8, 13, 13) (64, 8, 13, 13)\n",
      "aaaaaaa1 (64, 4, 30, 30) (64, 4, 30, 30)\n",
      "bbbbbbbbbbb1 (4, 30, 30) (64, 4, 30, 30)\n",
      "bbbbbbbbbbb2 (4, 30, 30) (64, 4, 30, 30)\n",
      "(64, 1, 30, 30)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 57600 into shape (4,30,30)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m nn \u001b[38;5;241m=\u001b[39m NeuralNetwork(layers_size\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m392\u001b[39m,\u001b[38;5;241m10\u001b[39m],activations \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m], lossFunction \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcrossEntropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, l_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m) \u001b[38;5;66;03m# 8*7*7 = 392\u001b[39;00m\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m Model([CNN1,pool1,CNN2,pool2, flatten,nn])\n\u001b[1;32m---> 10\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_validation\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_validation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mtest(x_test,y_test)\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\CNN_autograd.py:96\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, x_train, y_train, x_val, y_val, batch_size, epochs)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layers \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m     92\u001b[0m   output \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mforward(output)\n\u001b[1;32m---> 96\u001b[0m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layers \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m     99\u001b[0m   layers\u001b[38;5;241m.\u001b[39mupdate_parameter()\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:347\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, backward_grad)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m backward_grad\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepends_on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackward_grad\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:235\u001b[0m, in \u001b[0;36mTensor.softmax.<locals>._backward\u001b[1;34m(grad)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[0;32m    234\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (result\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m-\u001b[39m grad) \u001b[38;5;241m/\u001b[39m grad\u001b[38;5;241m.\u001b[39msize\n\u001b[1;32m--> 235\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:347\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, backward_grad)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m backward_grad\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepends_on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackward_grad\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:49\u001b[0m, in \u001b[0;36mTensor.__add__.<locals>._backward\u001b[1;34m(grad)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;28mprint\u001b[39m(new_other_grad\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     48\u001b[0m         new_other_grad \u001b[38;5;241m=\u001b[39m new_other_grad\u001b[38;5;241m.\u001b[39mreshape(other\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 49\u001b[0m \u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_other_grad\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:347\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, backward_grad)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m backward_grad\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepends_on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackward_grad\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:126\u001b[0m, in \u001b[0;36mTensor.dot.<locals>._backward\u001b[1;34m(grad)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m other\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[0;32m    125\u001b[0m     other_grad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(np\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata), grad)\n\u001b[1;32m--> 126\u001b[0m     \u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother_grad\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:347\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, backward_grad)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m backward_grad\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepends_on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackward_grad\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:22\u001b[0m, in \u001b[0;36mTensor.T.<locals>._backward\u001b[1;34m(grad)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_backward\u001b[39m(grad):\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[1;32m---> 22\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:347\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, backward_grad)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m backward_grad\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepends_on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackward_grad\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:334\u001b[0m, in \u001b[0;36mTensor.flatten.<locals>._backward\u001b[1;34m(grad)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[0;32m    333\u001b[0m     grad_input \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39mreshape(input_shape)\n\u001b[1;32m--> 334\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:347\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, backward_grad)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m backward_grad\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepends_on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackward_grad\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:321\u001b[0m, in \u001b[0;36mTensor.maxpooling.<locals>._backward\u001b[1;34m(grad)\u001b[0m\n\u001b[0;32m    318\u001b[0m                         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[n, c, h, w] \u001b[38;5;241m==\u001b[39m max_val:\n\u001b[0;32m    319\u001b[0m                             grad_input[n, c, h, w] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m grad[n, c, i, j]\n\u001b[1;32m--> 321\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:347\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, backward_grad)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m backward_grad\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepends_on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackward_grad\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:164\u001b[0m, in \u001b[0;36mTensor.relu.<locals>._backward\u001b[1;34m(grad)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_backward\u001b[39m(grad):\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[1;32m--> 164\u001b[0m       \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:347\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, backward_grad)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m backward_grad\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepends_on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackward_grad\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:40\u001b[0m, in \u001b[0;36mTensor.__add__.<locals>._backward\u001b[1;34m(grad)\u001b[0m\n\u001b[0;32m     38\u001b[0m         new_self_grad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(grad, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     39\u001b[0m         new_self_grad \u001b[38;5;241m=\u001b[39m new_self_grad\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_self_grad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m other\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbbbbbbbbbb1\u001b[39m\u001b[38;5;124m\"\u001b[39m, other\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape, grad\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:347\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, backward_grad)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m backward_grad\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepends_on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackward_grad\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:272\u001b[0m, in \u001b[0;36mTensor.conv.<locals>._backward\u001b[1;34m(grad)\u001b[0m\n\u001b[0;32m    270\u001b[0m           \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m    271\u001b[0m               grad_input[n][j] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m correlate2d(grad_padded[n][i],flipped_kernel[i][j],mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 272\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m other\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[0;32m    274\u001b[0m   grad_kernel \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(other\u001b[38;5;241m.\u001b[39mdata)\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:347\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, backward_grad)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m backward_grad\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepends_on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackward_grad\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:321\u001b[0m, in \u001b[0;36mTensor.maxpooling.<locals>._backward\u001b[1;34m(grad)\u001b[0m\n\u001b[0;32m    318\u001b[0m                         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[n, c, h, w] \u001b[38;5;241m==\u001b[39m max_val:\n\u001b[0;32m    319\u001b[0m                             grad_input[n, c, h, w] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m grad[n, c, i, j]\n\u001b[1;32m--> 321\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:347\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, backward_grad)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m backward_grad\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepends_on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackward_grad\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:164\u001b[0m, in \u001b[0;36mTensor.relu.<locals>._backward\u001b[1;34m(grad)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_backward\u001b[39m(grad):\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[1;32m--> 164\u001b[0m       \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:347\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, backward_grad)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m backward_grad\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepends_on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackward_grad\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:48\u001b[0m, in \u001b[0;36mTensor.__add__.<locals>._backward\u001b[1;34m(grad)\u001b[0m\n\u001b[0;32m     46\u001b[0m         new_other_grad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(grad, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;28mprint\u001b[39m(new_other_grad\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 48\u001b[0m         new_other_grad \u001b[38;5;241m=\u001b[39m \u001b[43mnew_other_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m other\u001b[38;5;241m.\u001b[39mbackward(new_other_grad)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 57600 into shape (4,30,30)"
     ]
    }
   ],
   "source": [
    "CNN1 = Convolutional(input_shape = (3,32,32), kernel_size = 3, output_depth = 4, l_rate = 0.01, activeFuncion = \"relu\")\n",
    "pool1 = MaxPoolingLayer(2)\n",
    "CNN2 = Convolutional(input_shape = (4,15,15), kernel_size = 3,output_depth = 8, l_rate = 0.01, activeFuncion = \"relu\")\n",
    "pool2 = MaxPoolingLayer(2)\n",
    "flatten = Flattening()\n",
    "nn = NeuralNetwork(layers_size=[392,10],activations = [\"softmax\"], lossFunction = \"crossEntropy\", l_rate = 0.01) # 8*7*7 = 392\n",
    "\n",
    "\n",
    "model = Model([CNN1,pool1,CNN2,pool2, flatten,nn])\n",
    "model.train(x_train,y_train,x_validation,y_validation, batch_size = 64, epochs = 100)\n",
    "model.test(x_test,y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

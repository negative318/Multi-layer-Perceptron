{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1, 28, 28) (10, 1000)\n",
      "(1000, 1, 28, 28) (10, 1000)\n",
      "(10000, 1, 28, 28) (10, 10000)\n"
     ]
    }
   ],
   "source": [
    "from MLP_autograd import *\n",
    "from CNN_autograd import *\n",
    "from keras.datasets import mnist\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "\n",
    "def one_hot(Y):\n",
    "  one_hot_Y = np.zeros((Y.size,np.max(Y) + 1))\n",
    "  one_hot_Y[np.arange(Y.size),Y] = 1\n",
    "  one_hot_Y = one_hot_Y.T\n",
    "  return one_hot_Y\n",
    "\n",
    "\n",
    "y_train = one_hot(y_train)\n",
    "y_test = one_hot(y_test)\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "x_validation = x_train[59000:60000]\n",
    "y_validation = y_train[:,59000:60000]\n",
    "x_train = x_train[0:1000]\n",
    "y_train = y_train[:,0:1000]\n",
    "\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0],1,28,28)\n",
    "x_validation = x_validation.reshape(x_validation.shape[0],1,28,28)\n",
    "x_test = x_test.reshape(x_test.shape[0],1,28,28)\n",
    "\n",
    "# x_train = Tensor(x_train.reshape(x_train.shape[0],1,28,28), requires_grad=True)\n",
    "# x_validation = Tensor(x_validation.reshape(x_validation.shape[0],1,28,28), requires_grad=True)\n",
    "# x_test = Tensor(x_test.reshape(x_test.shape[0],1,28,28), requires_grad=True)\n",
    "\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_validation.shape, y_validation.shape)\n",
    "print(x_test.shape,y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "CNN1 = Convolutional(input_shape = (1,28,28), kernel_size = 3, output_depth = 4, l_rate = 0.0001, activeFuncion = \"relu\")\n",
    "pool1 = MaxPoolingLayer(2)\n",
    "CNN2 = Convolutional(input_shape = (4,13,13), kernel_size = 3,output_depth = 8, l_rate = 0.0001, activeFuncion = \"relu\")\n",
    "pool2 = MaxPoolingLayer(2)\n",
    "flatten = Flattening()\n",
    "nn = NeuralNetwork(layers_size=[288,10],activations = [\"softmax\"], lossFunction = \"crossEntropy\", l_rate = 0.0001) # 8*6*6 = 288\n",
    "\n",
    "# a = Dense()\n",
    "\n",
    "# a.add(CNN1)\n",
    "# a.add(pool1)\n",
    "# a.add(CNN2)\n",
    "# a.add(flatten)\n",
    "\n",
    "# a.forward()\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 11.380958169882202 accuracy: 0.640625\n",
      "loss: 2.5020193370648642 accuracy: 0.0\n",
      "loss: 2.6028749067278896 accuracy: 0.0\n",
      "loss: 2.4531054201332347 accuracy: 0.0\n",
      "loss: 2.5387073301550873 accuracy: 0.0\n",
      "loss: 2.6521986279639775 accuracy: 0.0\n",
      "loss: 2.601941324291772 accuracy: 0.0\n",
      "loss: 2.53391349438427 accuracy: 0.0\n",
      "loss: 2.5359462681331983 accuracy: 0.0\n",
      "loss: 2.522032863942237 accuracy: 0.0\n",
      "loss: 2.3842304294703207 accuracy: 0.0\n",
      "loss: 2.6053786835272916 accuracy: 0.0\n",
      "loss: 2.57002765877085 accuracy: 0.0\n",
      "loss: 2.3927422636430413 accuracy: 0.0\n",
      "loss: 2.4159819318847675 accuracy: 0.0\n",
      "loss: 2.3542776838063255 accuracy: 0.0\n",
      "loss: 2.5912031242793443 accuracy: 0.0\n",
      "loss: 2.5020088687897624 accuracy: 0.0\n",
      "loss: 2.6028618099563534 accuracy: 0.0\n",
      "loss: 2.453096463998648 accuracy: 0.0\n",
      "loss: 2.5386962464756886 accuracy: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m output \u001b[38;5;241m=\u001b[39m CNN1\u001b[38;5;241m.\u001b[39mforward(Tensor(x_batch, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m     12\u001b[0m output \u001b[38;5;241m=\u001b[39m pool1\u001b[38;5;241m.\u001b[39mforward(output)\n\u001b[1;32m---> 13\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mCNN2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m output \u001b[38;5;241m=\u001b[39m pool2\u001b[38;5;241m.\u001b[39mforward(output)\n\u001b[0;32m     15\u001b[0m output \u001b[38;5;241m=\u001b[39m flatten\u001b[38;5;241m.\u001b[39mforward(output)\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\CNN_autograd.py:53\u001b[0m, in \u001b[0;36mConvolutional.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m     52\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m---> 53\u001b[0m   output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactive(output)\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:248\u001b[0m, in \u001b[0;36mTensor.conv\u001b[1;34m(self, other, stride, padding)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconv\u001b[39m(\u001b[38;5;28mself\u001b[39m, other,stride \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    242\u001b[0m     output_shape \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    243\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],  \u001b[38;5;66;03m# Number of examples\u001b[39;00m\n\u001b[0;32m    244\u001b[0m         other\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],  \u001b[38;5;66;03m# Number of output channels\u001b[39;00m\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m other\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m padding \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,  \u001b[38;5;66;03m# Height\u001b[39;00m\n\u001b[0;32m    246\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m other\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m padding \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Width\u001b[39;00m\n\u001b[0;32m    247\u001b[0m     )\n\u001b[1;32m--> 248\u001b[0m     output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(output_shape)\n\u001b[0;32m    250\u001b[0m     padded_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, ((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), (padding, padding), (padding, padding)), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "def get_accuracy(predictions,output):\n",
    "    return np.sum(predictions == output) / output.shape[1]\n",
    "\n",
    "for i in range (epochs):\n",
    "\n",
    "    for i in range(0,x_train.shape[0],64):\n",
    "        x_batch = x_train[i:min(i+batch_size,x_train.shape[0])]\n",
    "        y_batch = y_train[:,i:min(i+batch_size,x_train.shape[0])] # 10x32\n",
    "\n",
    "        output = CNN1.forward(Tensor(x_batch, requires_grad=True))\n",
    "        output = pool1.forward(output)\n",
    "        output = CNN2.forward(output)\n",
    "        output = pool2.forward(output)\n",
    "        output = flatten.forward(output)\n",
    "        output = nn.forward(output)\n",
    "\n",
    "        output.backward(y_batch)\n",
    "        # print(CNN1.bias)\n",
    "\n",
    "        nn.update_parameter()\n",
    "        CNN2.update_parameter()\n",
    "        CNN1.update_parameter()\n",
    "\n",
    "        print(\"loss:\", -np.sum(y_batch * np.log(output.data+1e-6)) / y_batch.shape[1], \"accuracy:\", get_accuracy(output.data,y_batch))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

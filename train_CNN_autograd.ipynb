{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1, 28, 28) (10, 1000)\n",
      "(1000, 1, 28, 28) (10, 1000)\n",
      "(10000, 1, 28, 28) (10, 10000)\n"
     ]
    }
   ],
   "source": [
    "from MLP_autograd import *\n",
    "from CNN_autograd import *\n",
    "from keras.datasets import mnist\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "\n",
    "def one_hot(Y):\n",
    "  one_hot_Y = np.zeros((Y.size,np.max(Y) + 1))\n",
    "  one_hot_Y[np.arange(Y.size),Y] = 1\n",
    "  one_hot_Y = one_hot_Y.T\n",
    "  return one_hot_Y\n",
    "\n",
    "\n",
    "y_train = one_hot(y_train)\n",
    "y_test = one_hot(y_test)\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "x_validation = x_train[59000:60000]\n",
    "y_validation = y_train[:,59000:60000]\n",
    "x_train = x_train[0:1000]\n",
    "y_train = y_train[:,0:1000]\n",
    "\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0],1,28,28)\n",
    "x_validation = x_validation.reshape(x_validation.shape[0],1,28,28)\n",
    "x_test = x_test.reshape(x_test.shape[0],1,28,28)\n",
    "\n",
    "# x_train = Tensor(x_train.reshape(x_train.shape[0],1,28,28), requires_grad=True)\n",
    "# x_validation = Tensor(x_validation.reshape(x_validation.shape[0],1,28,28), requires_grad=True)\n",
    "# x_test = Tensor(x_test.reshape(x_test.shape[0],1,28,28), requires_grad=True)\n",
    "\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_validation.shape, y_validation.shape)\n",
    "print(x_test.shape,y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "CNN1 = Convolutional(input_shape = (1,28,28), kernel_size = 3, output_depth = 4, l_rate = 0.01, activeFuncion = \"relu\")\n",
    "pool1 = MaxPoolingLayer(2)\n",
    "CNN2 = Convolutional(input_shape = (4,13,13), kernel_size = 3,output_depth = 8, l_rate = 0.01, activeFuncion = \"relu\")\n",
    "pool2 = MaxPoolingLayer(2)\n",
    "flatten = Flattening()\n",
    "nn = NeuralNetwork(layers_size=[288,10],activations = [\"softmax\"], lossFunction = \"crossEntropy\", l_rate = 0.01) # 8*6*6 = 288\n",
    "\n",
    "# a = Dense()\n",
    "\n",
    "# a.add(CNN1)\n",
    "# a.add(pool1)\n",
    "# a.add(CNN2)\n",
    "# a.add(flatten)\n",
    "\n",
    "# a.forward()\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 11.733406122394658 accuracy: 0.087\n",
      "loss: 11.673104463054061 accuracy: 0.078\n",
      "loss: 11.630961451360031 accuracy: 0.078\n",
      "loss: 11.59742198949623 accuracy: 0.078\n",
      "loss: 11.570411682954907 accuracy: 0.075\n",
      "loss: 11.546464241301303 accuracy: 0.073\n",
      "loss: 11.522704370674102 accuracy: 0.074\n",
      "loss: 11.487288694192083 accuracy: 0.073\n",
      "loss: 11.458789700864028 accuracy: 0.076\n",
      "loss: 11.437578564891714 accuracy: 0.075\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m output \u001b[38;5;241m=\u001b[39m flatten\u001b[38;5;241m.\u001b[39mforward(output)\n\u001b[0;32m      9\u001b[0m output \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mforward(output)\n\u001b[1;32m---> 11\u001b[0m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# print(CNN1.bias)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m nn\u001b[38;5;241m.\u001b[39mupdate_parameter()\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:343\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, backward_grad)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m backward_grad\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepends_on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 343\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackward_grad\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:233\u001b[0m, in \u001b[0;36mTensor.softmax.<locals>._backward\u001b[1;34m(grad)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[0;32m    232\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (result\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m-\u001b[39m grad) \u001b[38;5;241m/\u001b[39m grad\u001b[38;5;241m.\u001b[39msize\n\u001b[1;32m--> 233\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:343\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, backward_grad)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m backward_grad\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepends_on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 343\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackward_grad\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:39\u001b[0m, in \u001b[0;36mTensor.__add__.<locals>._backward\u001b[1;34m(grad)\u001b[0m\n\u001b[0;32m     37\u001b[0m         new_self_grad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(grad, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Summing along the second axis\u001b[39;00m\n\u001b[0;32m     38\u001b[0m         new_self_grad \u001b[38;5;241m=\u001b[39m new_self_grad\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_self_grad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m other\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m other\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m grad\u001b[38;5;241m.\u001b[39mshape:\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;66;03m# Reduce the grad shape to match other.data.shape\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:343\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, backward_grad)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m backward_grad\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepends_on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 343\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackward_grad\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:128\u001b[0m, in \u001b[0;36mTensor.dot.<locals>._backward\u001b[1;34m(grad)\u001b[0m\n\u001b[0;32m    125\u001b[0m other_grad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(np\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata), grad)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# print(\"bbbbbbbbbbbbbb\", np.sum(other_grad))\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# print(\"bbbbbbbbbbbbbb\", other_grad)\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m \u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother_grad\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:343\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, backward_grad)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m backward_grad\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepends_on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 343\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackward_grad\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:22\u001b[0m, in \u001b[0;36mTensor.T.<locals>._backward\u001b[1;34m(grad)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_backward\u001b[39m(grad):\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[1;32m---> 22\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:343\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, backward_grad)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m backward_grad\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepends_on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 343\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackward_grad\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:330\u001b[0m, in \u001b[0;36mTensor.flatten.<locals>._backward\u001b[1;34m(grad)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[0;32m    329\u001b[0m     grad_input \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39mreshape(input_shape)\n\u001b[1;32m--> 330\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:343\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, backward_grad)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m backward_grad\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepends_on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 343\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackward_grad\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:317\u001b[0m, in \u001b[0;36mTensor.maxpooling.<locals>._backward\u001b[1;34m(grad)\u001b[0m\n\u001b[0;32m    314\u001b[0m                         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[n, c, h, w] \u001b[38;5;241m==\u001b[39m max_val:\n\u001b[0;32m    315\u001b[0m                             grad_input[n, c, h, w] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m grad[n, c, i, j]\n\u001b[1;32m--> 317\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:343\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, backward_grad)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m backward_grad\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepends_on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 343\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackward_grad\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:267\u001b[0m, in \u001b[0;36mTensor.conv.<locals>._backward\u001b[1;34m(grad)\u001b[0m\n\u001b[0;32m    265\u001b[0m           \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(other\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m    266\u001b[0m               grad_input[n][j] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m correlate2d(grad_padded[n][i],flipped_kernel[i][j],mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 267\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m other\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[0;32m    269\u001b[0m   grad_kernel \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(other\u001b[38;5;241m.\u001b[39mdata)\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:343\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, backward_grad)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m backward_grad\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepends_on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 343\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackward_grad\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dotie\\Máy tính\\Multi-layer-Perceptron\\autograd.py:311\u001b[0m, in \u001b[0;36mTensor.maxpooling.<locals>._backward\u001b[1;34m(grad)\u001b[0m\n\u001b[0;32m    309\u001b[0m w_start \u001b[38;5;241m=\u001b[39m j \u001b[38;5;241m*\u001b[39m pool_size\n\u001b[0;32m    310\u001b[0m w_end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(w_start \u001b[38;5;241m+\u001b[39m pool_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m--> 311\u001b[0m max_val \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43mh_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43mw_end\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(h_start, h_end):\n\u001b[0;32m    313\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(w_start, w_end):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "def get_accuracy(predictions,output):\n",
    "    return np.sum(predictions == output) / output.shape[1]\n",
    "\n",
    "for i in range (epochs):\n",
    "\n",
    "    for i in range(0,x_train.shape[0],64):\n",
    "        x_batch = x_train[i:min(i+batch_size,x_train.shape[0])]\n",
    "        y_batch = y_train[:,i:min(i+batch_size,x_train.shape[0])] # 10x32\n",
    "\n",
    "        output = CNN1.forward(Tensor(x_batch, requires_grad=True))\n",
    "        output = pool1.forward(output)\n",
    "        output = CNN2.forward(output)\n",
    "        output = pool2.forward(output)\n",
    "        output = flatten.forward(output)\n",
    "        output = nn.forward(output)\n",
    "\n",
    "        output.backward(y_batch)\n",
    "        # print(CNN1.bias)\n",
    "\n",
    "        nn.update_parameter()\n",
    "        CNN2.update_parameter()\n",
    "        CNN1.update_parameter()\n",
    "\n",
    "        print(\"loss:\", -np.sum(y_batch * np.log(output.data+1e-6)) / y_batch.shape[1], \"accuracy:\", get_accuracy(output.data,y_batch))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

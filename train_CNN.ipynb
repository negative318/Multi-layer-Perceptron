{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MLP import *\n",
    "from CNN import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "\n",
    "def one_hot(Y):\n",
    "  one_hot_Y = np.zeros((Y.size,np.max(Y) + 1))\n",
    "  one_hot_Y[np.arange(Y.size),Y] = 1\n",
    "  one_hot_Y = one_hot_Y.T\n",
    "  return one_hot_Y\n",
    "\n",
    "num_test = 1000\n",
    "y_train = one_hot(y_train)\n",
    "y_test = one_hot(y_test)\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "x_validation = x_train[59000:60000]\n",
    "y_validation = y_train[:,59000:60000]\n",
    "x_train = x_train[0:num_test]\n",
    "y_train = y_train[:,0:num_test]\n",
    "\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape,y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 32\n",
    "CNN1 = Convolutional((1,28,28),3,4,0.1)\n",
    "pool1 = MaxPoolingLayer(2)\n",
    "CNN2 = Convolutional((4,13,13),3,8,0.1)\n",
    "pool2 = MaxPoolingLayer(2)\n",
    "flatten = Flattening()\n",
    "nn = NeuralNetwork(layers_size=[288,10],activations = [\"\", \"softmax\"], loss = \"crossEntropy\", l_rate = 0.1) # 8*6*6 = 576\n",
    "\n",
    "\n",
    "\n",
    "model = Model([CNN1,pool1,CNN2,pool2],nn)\n",
    "model.train(x_train,y_train,x_validation,y_validation, batch_size, epochs, 0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test(x_validation, y_validation)\n",
    "\n",
    "model.test(x_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
